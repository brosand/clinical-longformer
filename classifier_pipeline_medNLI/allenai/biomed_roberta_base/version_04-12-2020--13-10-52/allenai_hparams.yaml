accumulate_grad_batches: 2
batch_size: 12
encoder_learning_rate: 1.0e-05
encoder_model: allenai/biomed_roberta_base
fast_dev_run: false
gpus: 1
learning_rate: 3.0e-05
loader_workers: 8
max_epochs: 10
max_tokens: 512
max_tokens_longformer: 4096
metric_mode: max
monitor: val_acc
nr_frozen_epochs: 0
patience: 5
save_top_k: 1
seed: 3
single_label_encoding: default
transformer_type: bert
